# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## SESSION INITIALIZATION (MANDATORY FIRST STEP)

### **BP-0: Session Role Selection Protocol (BLOCKING ENFORCEMENT)**

**EVERY NEW SESSION MUST START WITH ROLE SELECTION - NO EXCEPTIONS**

**BLOCKING RULE**: Claude CANNOT proceed with any technical task, code analysis, or implementation work until a role has been explicitly selected and confirmed.

**Session Greeting Template:**

```
üö´ SESSION BLOCKED - ROLE SELECTION REQUIRED

To provide expert-level assistance, I must first establish my role for this session.

**Select Primary Role:**

**Backend Engineering** - APIs, databases, system architecture, performance optimization
**Data Science** - ML models, embeddings, vector optimization, research analysis
**DevOps Engineering** - Deployment, monitoring, CI/CD, infrastructure management
**Frontend Development** - UI/UX, client-side logic, user experience design
**Security Engineering** - Authentication, authorization, vulnerability assessment
**System Architecture** - High-level design, scalability, component relationships
**Product Management** - Requirements analysis, feature prioritization, roadmap planning

Which role should I adopt? (Required before proceeding)
```

**Enforcement Mechanism:**
- If user attempts to bypass role selection, respond: "üö´ Role selection required. Please choose from the available roles before I can assist with technical tasks."
- Only after role confirmation, proceed with: "‚úÖ [ROLE] adopted. Ready to proceed with [role-specific] expertise."

**Intelligent Role Suggestion:**
Analyze the user's request topic and intelligently suggest the most appropriate role with clear rationale.

**Role Context Establishment:**

1. **Analyze request topic** - determine most relevant expertise area
2. **Provide intelligent suggestion** - recommend role with clear rationale
3. **Wait for user role selection** - cannot proceed without selection
4. **Confirm role adoption** - state selected expertise clearly
5. **Update session context** - document role in active_context.md
6. **Apply role-specific knowledge** - all subsequent responses use chosen expertise
7. **Enable role switching** - allow mid-session role changes if requested

**Role-Specific Confidence Thresholds:**

- **Backend Engineer**: High confidence in APIs, databases, performance (95%+ threshold)
- **Data Scientist**: High confidence in ML, embeddings, research (95%+ threshold)
- **DevOps Engineer**: High confidence in deployment, monitoring, infrastructure (95%+ threshold)
- **Others**: Apply appropriate confidence thresholds per expertise domain

**Role Context Templates:**

**Backend Engineer Adoption:**

```
üîß ROLE ADOPTED: Backend Engineer
Expertise Focus: APIs, databases, system architecture, performance optimization
Knowledge Areas: FastAPI, Qdrant, async patterns, scalability, data consistency
Session Context: Backend engineering perspective applied to all tasks
Ready to assist with backend-focused solutions.
```

**Data Scientist Adoption:**

```
üß† ROLE ADOPTED: Data Scientist
Expertise Focus: ML models, embeddings, vector optimization, research analysis
Knowledge Areas: BGE-M3, OpenCLIP, vector similarity, model evaluation, benchmarks
Session Context: Data science perspective applied to all tasks
Ready to assist with ML and research-focused solutions.
```

**DevOps Engineer Adoption:**

```
‚öôÔ∏è ROLE ADOPTED: DevOps Engineer
Expertise Focus: Deployment, monitoring, CI/CD, infrastructure management
Knowledge Areas: Docker, Kubernetes, Prometheus, GitHub Actions, production operations
Session Context: DevOps perspective applied to all tasks
Ready to assist with deployment and operational solutions.
```

**Mid-Session Role Switching:**

```
User Request: "Switch to [NEW_ROLE] for this task"
Agent Response:
üé≠ ROLE SWITCH REQUESTED
Current Role: [CURRENT_ROLE]
Requested Role: [NEW_ROLE]

Switching to [NEW_ROLE] expertise...
New Focus: [role-specific focus areas]
Session context updated: [NEW_ROLE] mode active
Ready to proceed with [NEW_ROLE] perspective.
```

**Session Context Documentation:**
Role selection must be documented in project memory files:

**tasks/active_context.md Update:**

```markdown
## Current Session Context

**Active Role**: [Selected Role]
**Role Focus**: [Expertise areas]
**Session Started**: [Date/Time]
**Key Priorities**: [Role-specific current priorities]
**Role-Specific Goals**: [What this session aims to accomplish from this role's perspective]
```

## MANDATORY PROTOCOL ENFORCEMENT (ZERO TOLERANCE FOR VIOLATIONS)

### **üõë RULE VIOLATION = IMMEDIATE STOP + RULE CITATION**

### **VIOLATION PHRASE DETECTION (AUTO-STOP)**

**IF USER SAYS**: "skip the questions", "don't ask questions", "just implement", "no questions"
**MANDATORY RESPONSE**:

```
üõë RULE VIOLATION DETECTED: BP-3 prohibits skipping clarification questions.
CLAUDE.md Rule BP-3 states: "NEVER start research or implementation without clarification"
I cannot proceed without clarification questions. This is non-negotiable.
```

### BP-1 (MUST): Mode Detection, Protocol Activation, and TodoWrite Enforcement

**BEFORE ANYTHING ELSE** - Detect mode and state protocol:

- Any broad optimization/improvement request = **@PLAN_MODE** (NOT @CODE_MODE)
- Specific implementation task = **@CODE_MODE**
- **ALWAYS** state: "Activating [X] protocol per CLAUDE.md rules"

**MANDATORY TODOWRITE USAGE**:
- **ANY task with 3+ distinct steps** = MUST use TodoWrite
- **ANY task spanning multiple exchanges** = MUST use TodoWrite
- **ANY complex implementation work** = MUST use TodoWrite
- **VIOLATION RESPONSE**: "üõë TodoWrite required per CLAUDE.md BP-1. Creating task list now."

**TodoWrite Trigger Examples**:
- "Implement comprehensive title vector test" ‚Üí TodoWrite required
- "Analyze data structure and create tests" ‚Üí TodoWrite required
- "Fix multimodal testing with field combinations" ‚Üí TodoWrite required

### BP-2 (MUST): Context Loading Before Any Action

**IMMEDIATELY** after protocol activation, load context:

```
Loading required context per BP-2:
‚úì docs/architecture.md
‚úì docs/product_requirement_docs.md
‚úì docs/technical.md
‚úì tasks/active_context.md
‚úì tasks/tasks_plan.md
```

### BP-3 (MUST): Clarification Questions - ZERO EXCEPTIONS

**SEQUENCE IS NON-NEGOTIABLE**: Context ‚Üí Questions ‚Üí Wait for Answers ‚Üí Then Proceed

**MANDATORY QUESTIONS** (cannot be skipped even if user requests):

1. **Specific Scope**: What exactly needs to be done?
2. **Priority/Urgency**: What's most critical?
3. **Constraints**: Timeline, resources, limitations?
4. **Success Criteria**: How do we measure success?
5. **Integration**: How should this fit with existing systems?

**ENFORCEMENT**: If user tries to skip questions, cite BP-3 and refuse to proceed

### BP-4 (MUST): Architecture Validation

**FOR ANY SYSTEM CHANGES** - validate against docs/architecture.md:

- Parse mermaid diagrams
- Check component boundaries
- **STOP** if violations detected

## Rules System - Compressed Protocols

### Mode Tokens (with mandatory validation)

- `@PLAN_MODE` ‚Üí **MUST** Load docs/ + tasks/ ‚Üí **MUST** Ask Clarification Questions ‚Üí Research ‚Üí Strategy ‚Üí Validate ‚Üí Document
- `@CODE_MODE` ‚Üí **MUST** Load context + src/ ‚Üí **MUST** Analyze deps ‚Üí Plan ‚Üí Simulate ‚Üí Test ‚Üí Document

### Protocol Tokens

- `@PRE_IMPL` ‚Üí **MUST** Read docs/ + tasks/ + src/ context + dependency analysis + flow analysis
- `@ARCH_VALID` ‚Üí **MUST** Parse mermaid from docs/architecture.md ‚Üí validate ‚Üí **STOP** if violations
- `@SIM_TEST` ‚Üí **MUST** Dry run changes ‚Üí validate no breakage ‚Üí fix before implement
- `@MEM_UPDATE` ‚Üí **MUST** Review memory files ‚Üí update context ‚Üí document patterns

### Intelligence Tokens (AUTOMATICALLY ENFORCED)

### **üîç ANTI-PATTERN AUTO-DETECTION (IMMEDIATE STOP)**

**Trigger Phrases** ‚Üí **MANDATORY STOP RESPONSE**:

```
"optimize everything" ‚Üí üõë ANTI-PATTERN: Premature optimization detected per CLAUDE.md
"make it faster" ‚Üí üõë ANTI-PATTERN: Need specific bottlenecks and baselines first
"improve performance" ‚Üí üõë ANTI-PATTERN: Must identify specific performance issues
"fix all issues" ‚Üí üõë ANTI-PATTERN: Need issue prioritization and scope
```

### **‚ö†Ô∏è ERROR CONTEXT MANDATORY CHECK**

**ANY mention of**: "error", "failure", "broken", "not working", "failing"
**REQUIRED FIRST ACTION**:

```
Checking @ERRORS per CLAUDE.md rules...
From rules/error-documentation.md: [list relevant known issues]
Applying known solutions before new investigation...
```

### **üìö LESSONS AUTO-APPLICATION**

**MUST apply patterns** from rules/lessons-learned.md for:

- Performance requests ‚Üí async-first, config-driven patterns
- Architecture changes ‚Üí graceful degradation principles
- Implementation ‚Üí multi-vector design philosophy
- Error handling ‚Üí context-rich error messages

### **üîÑ SELF-UPDATE TRIGGERS**

- Pattern violations detected ‚Üí Update rules
- New successful patterns ‚Üí Document in lessons-learned
- Error resolutions ‚Üí Update error-documentation

### Execution Pattern (WITH VALIDATION GATES)

```
[NEW SESSION] ‚Üí BP-0 Role Selection ‚Üí Role Context Established ‚Üí
[TASK REQUEST] ‚Üí Mode Detection (STATE EXPLICITLY) ‚Üí
Load @[MODE]_MODE ‚Üí VALIDATE Context Loaded ‚Üí
Apply @PRE_IMPL ‚Üí VALIDATE @ARCH_VALID ‚Üí
Execute with @LESSONS + @ERRORS (role-specific) ‚Üí @SIM_TEST ‚Üí
Implement ‚Üí @MEM_UPDATE ‚Üí Document role-specific patterns
```

### üîí MANDATORY VALIDATION GATES (CANNOT BE BYPASSED)

**GATE 0: SESSION ROLE VALIDATION**

- [ ] üé≠ Session role selected and confirmed
- [ ] üé≠ Role context established and documented
- [ ] üé≠ Role-specific confidence thresholds applied
- [ ] üé≠ Session context updated in memory files

**GATE 1: TODOWRITE VALIDATION**

- [ ] üìã Task complexity assessed (3+ steps = TodoWrite required)
- [ ] üìã TodoWrite created if required
- [ ] üìã Task progress tracked throughout execution
- [ ] üìã TodoWrite updated in real-time

**GATE 2: RULE VIOLATION DETECTION**

- [ ] ‚úã Check for "skip questions" phrases ‚Üí STOP if detected
- [ ] ‚úã Check for anti-pattern triggers ‚Üí STOP if detected
- [ ] ‚úã Check for error mentions ‚Üí Check @ERRORS first

**GATE 3: PROTOCOL COMPLIANCE**

- [ ] üìã Protocol explicitly stated with CLAUDE.md reference
- [ ] üìã Context files loaded with checkmark confirmation
- [ ] üìã Clarification questions asked (MANDATORY - no exceptions)
- [ ] üìã User responses received before proceeding

**GATE 4: ARCHITECTURE VALIDATION**

- [ ] üèóÔ∏è Architecture constraints checked against docs/architecture.md
- [ ] üèóÔ∏è Component boundaries validated
- [ ] üèóÔ∏è Interface contracts verified
- [ ] üèóÔ∏è Role-specific architectural considerations applied

### **üö® VIOLATION RESPONSE TEMPLATES**

**For TodoWrite violations:**

```
üõë TODOWRITE VIOLATION: Complex task detected per CLAUDE.md BP-1
Task has 3+ steps and requires TodoWrite for progress tracking.
Creating todo list now...
```

**For "skip questions" violations:**

```
üõë RULE VIOLATION: BP-3 Clarification Questions cannot be skipped
CLAUDE.md states: "NEVER start implementation without clarification"
This is non-negotiable. I need answers to proceed safely.
```

**For role selection violations:**

```
üö´ ROLE SELECTION REQUIRED: Cannot proceed with technical tasks per BP-0
Please select your preferred expertise role from the available options.
```

**For anti-pattern violations:**

```
üõë ANTI-PATTERN DETECTED: [specific pattern]
Per CLAUDE.md rules, I must clarify requirements first.
[Specific questions for this anti-pattern]
```

**For missing context:**

```
üõë PROTOCOL VIOLATION: Context loading required per BP-2
Loading context files now...
```

**Usage**: Reference tokens trigger full protocol expansion. **IMPORTANT**: Rules are recursive - they apply at every step.

## Repository Overview

This is a specialized microservice for semantic search over anime content using vector embeddings and Qdrant database. The service provides text, image, and multimodal search capabilities with production-ready features including health checks, monitoring, and CORS support.

## Development Commands

### Local Development Setup

```bash
# Install dependencies
uv sync

# Install with dev dependencies (includes pytest, mypy, etc.)
uv sync --extra dev

# Start Qdrant database only
docker compose -f docker/docker-compose.yml up -d qdrant

# Run service locally for development
uv run python -m src.main
```

### Docker Development (Recommended)

```bash
# Start full stack (service + database)
docker compose -f docker/docker-compose.yml up -d

# View logs
docker compose -f docker/docker-compose.yml logs -f vector-service

# Stop services
docker compose -f docker/docker-compose.yml down
```

### Testing and Quality

```bash
# Run tests
uv run pytest

# Run specific test file
uv run pytest test_filename.py

# Run tests with coverage
uv run pytest --cov=src

# Type checking (MANDATORY before commits)
uv run mypy --strict src/

# Code formatting
uv run black src/
uv run isort src/
uv run autoflake --remove-all-unused-imports --in-place --recursive src/
```

### Type Safety Protocol

**MANDATORY**: All code must pass strict mypy type checking before commits.

```bash
# Check all source files with strict typing
uv run mypy --strict src/ --show-error-codes

# Check specific file
uv run mypy --strict src/vector/text_processor.py --show-error-codes
```

**Type Safety Guidelines:**

- All function parameters and return values must be properly typed
- Use `Dict[str, Any]` instead of bare `Dict`
- Use `cast()` for external library types when needed
- Add null checks for Optional types before usage
- Test all type fixes with real functionality before committing

### Service Health Checks

```bash
# Check service health
curl http://localhost:8002/health

# Check Qdrant health
curl http://localhost:6333/health

# Get database statistics
curl http://localhost:8002/api/v1/admin/stats
```

## Architecture Overview

### Core Architecture Pattern

The service follows a layered microservice architecture with clear separation of concerns:

**API Layer** (`src/api/`) ‚Üí **Processing Layer** (`src/vector/`) ‚Üí **Database Layer** (Qdrant)

### Key Architectural Components

#### 1. FastAPI Application (`src/main.py`)

- Async application with lifespan management
- Global Qdrant client initialization with health checks
- CORS middleware and structured logging
- Graceful startup/shutdown with dependency validation

#### 2. Configuration System (`src/config/settings.py`)

- Pydantic-based settings with environment variable support
- Comprehensive validation for all configuration parameters
- Support for multiple embedding providers and models
- Performance tuning parameters (quantization, HNSW, batch sizes)

#### 3. Multi-Vector Processing (`src/vector/`)

- **QdrantClient**: Advanced vector database operations with quantization support
- **TextProcessor**: BGE-M3 embeddings for semantic text search (1024-dim)
- **VisionProcessor**: OpenCLIP ViT-L/14 embeddings for image search (768-dim)
- **Fine-tuning modules**: Character recognition, art style classification, genre enhancement

#### 4. API Endpoints (`src/api/`)

- **Search Router**: Text, image, and multimodal search endpoints
- **Similarity Router**: Content-based and visual similarity operations
- **Admin Router**: Database management, statistics, and reindexing

#### 5. Data Enrichment Pipeline (`src/enrichment/`)

- **API Helpers**: Integration with 6+ external anime APIs (AniList, Kitsu, AniDB, etc.)
- **Crawlers**: Heavy-duty browser automation using crawl4ai for robust data extraction
- **Scrapers**: Web scraping with Cloudflare bypass capabilities
- **Multi-stage AI Pipeline**: Modular prompt system for data enhancement
- **Auto-Agent Assignment**: Automatic agent ID assignment for concurrent processing with gap-filling logic

### Enrichment Pipeline Usage

**Script**: `run_enrichment.py` - Main entry point for programmatic enrichment

**Database**: Reads from `data/qdrant_storage/anime-offline-database.json` (39,244+ anime entries)

**Arguments**:
- `--index N`: Process anime at index N (0-based)
- `--title "Title"`: Search for anime by title (case-insensitive, partial match)
- `--file PATH`: Use custom database file (optional)
- `--agent "name"`: Specify agent directory name (optional, auto-generated if not provided)
- `--skip service1 service2`: Skip specific services (e.g., `--skip jikan anidb`)
- `--only service1 service2`: Only fetch specific services (e.g., `--only anime_planet`)

**Available Services**: `jikan`, `anilist`, `kitsu`, `anidb`, `anime_planet`, `anisearch`, `animeschedule`

**Example Usage**:
```bash
# Process first anime in database
python run_enrichment.py --index 0

# Process One Piece
python run_enrichment.py --title "One Piece"

# Use custom database
python run_enrichment.py --file custom.json --index 5

# Specify agent directory
python run_enrichment.py --title "Dandadan" --agent "Dandadan_test"

# Skip specific services
python run_enrichment.py --title "Dandadan" --skip animeschedule anidb

# Only fetch from specific services
python run_enrichment.py --title "Dandadan" --only anime_planet anisearch
```

**Notes**:
- `--skip` and `--only` are mutually exclusive
- **Auto-Agent Assignment**: Pipeline automatically assigns agent IDs using gap-filling logic if `--agent` not specified

### Stage Script Directory Detection

All stage scripts follow a consistent pattern for multi-agent concurrent processing. Each stage accepts an `agent_id` positional argument that specifies the directory name within the temp directory.

**Common Pattern**: `python process_stage<N>.py <agent_id> [--temp-dir <base>]`
- `agent_id`: Directory name (e.g., `One_agent1`, `Dandadan_agent1`)
- `--temp-dir`: Base directory path (default: `temp`) - optional

**Multi-agent Directory Structure**: `temp/<agent_id>/` (e.g., `temp/One_agent1/`, `temp/Dandadan_agent1>/`)

**Note**: When using `run_enrichment.py`, agent IDs are assigned automatically. Manual specification only needed for independent stage script execution.

#### Stage 1: Metadata Extraction (`process_stage1_metadata.py`)

**Arguments**: `agent_id` (positional), `--temp-dir` (default: `temp`), `--current-anime` (legacy support)

**Example Usage**:
```bash
# Recommended: Use agent_id
python process_stage1_metadata.py One_agent1

# Custom temp directory
python process_stage1_metadata.py One_agent1 --temp-dir custom_temp

# Legacy: Use file path
python process_stage1_metadata.py --current-anime temp/One_agent1/current_anime.json
```

#### Stage 2: Episode Processing (`process_stage2_episodes.py`)

**Arguments**: `agent_id` (positional), `--temp-dir` (default: `temp`)

**Required File**: `episodes_detailed.json` (must exist in agent directory)

**Example Usage**:
```bash
# Recommended: Use agent_id
python process_stage2_episodes.py One_agent1

# Custom temp directory
python process_stage2_episodes.py One_agent1 --temp-dir custom_temp
```

#### Stage 3: Relationship Processing (`process_stage3_relationships.py`)

**Arguments**: `agent_id` (positional), `--temp-dir` (default: `temp`), `--current-anime` (legacy support)

**Example Usage**:
```bash
# Recommended: Use agent_id
python process_stage3_relationships.py One_agent1

# Custom temp directory
python process_stage3_relationships.py One_agent1 --temp-dir custom_temp

# Legacy: Use file path
python process_stage3_relationships.py --current-anime temp/One_agent1/current_anime.json
```

#### Stage 4: Statistics Extraction (`process_stage4_statistics.py`)

**Arguments**: `agent_id` (positional), `--temp-dir` (default: `temp`)

**Example Usage**:
```bash
# Recommended: Use agent_id
python scripts/process_stage4_statistics.py Dandadan_agent1

# Custom temp directory
python scripts/process_stage4_statistics.py Dandadan_agent1 --temp-dir custom_temp
```

#### Stage 5: AI Character Matching (`process_stage5_characters.py`)

**Arguments**: `agent_id` (positional), `--temp-dir` (default: `temp`), `--restart` (optional flag)

**Example Usage**:
```bash
# Process with resume support (recommended)
python process_stage5_characters.py One_agent1

# Force restart from scratch
python process_stage5_characters.py One_agent1 --restart

# Custom temp directory
python process_stage5_characters.py One_agent1 --temp-dir custom_temp
```

### Multi-Vector Collection Design

The service uses a single Qdrant collection with named vectors:

- `text`: 1024-dimensional BGE-M3 embeddings for semantic search
- `image_vector`: 768-dimensional OpenCLIP ViT-L/14 embeddings for cover art, posters, banners
- `character_image_vector`: 768-dimensional OpenCLIP ViT-L/14 embeddings for character images

This design enables efficient multimodal search while maintaining data locality and reducing storage overhead.

### Configuration-Driven Model Selection

The service supports multiple embedding providers through configuration:

- **Text Models**: BGE-M3, BGE-small/base/large-v1.5, custom HuggingFace models
- **Vision Models**: OpenCLIP ViT-L/14, OpenCLIP ViT-B/32 (primary: ViT-L/14)
- **Provider Flexibility**: Easy switching between embedding providers per modality

### Performance Optimization Features

- **Vector Quantization**: Binary/Scalar/Product quantization for 40x speedup potential
- **HNSW Tuning**: Optimized parameters for anime-specific search patterns
- **Payload Indexing**: Fast filtering on genre, year, type, status fields
- **Hybrid Search**: Single-request API for combined text+image queries
- **GPU Acceleration**: Support for GPU-accelerated model inference

## Environment Variables

### Critical Configuration

- `QDRANT_URL`: Vector database URL (default: http://localhost:6333)
- `QDRANT_COLLECTION_NAME`: Collection name (default: anime_database)
- `TEXT_EMBEDDING_MODEL`: Text model (default: BAAI/bge-m3)
- `IMAGE_EMBEDDING_MODEL`: Image model (default: ViT-L-14/laion2b_s32b_b82k)

### Performance Tuning

- `QDRANT_ENABLE_QUANTIZATION`: Enable vector quantization (default: false)
- `QDRANT_QUANTIZATION_TYPE`: Quantization type (scalar, binary, product)
- `MODEL_WARM_UP`: Pre-load models during startup (default: false)
- `MAX_BATCH_SIZE`: Maximum batch size for operations (default: 500)

### Service Configuration

- `VECTOR_SERVICE_PORT`: Service port (default: 8002)
- `DEBUG`: Enable debug mode (default: true)
- `LOG_LEVEL`: Logging level (default: INFO)

## Memory Files System

This repository uses a comprehensive Memory Files system for project documentation. Always consult these files before making architectural changes or planning new features.

## Integration Points

### External Dependencies

- **Qdrant Database**: Primary vector storage (required)
- **HuggingFace Models**: Text and image embeddings (cached locally)
- **External APIs**: Optional enrichment from anime platforms

### Client Integration

- Python client library available in `client/` directory
- REST API with comprehensive OpenAPI documentation at `/docs`
- Health check endpoint at `/health` for load balancer integration
